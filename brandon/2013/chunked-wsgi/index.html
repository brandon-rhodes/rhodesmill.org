<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>WSGI and truncated chunked response bodies</title>
  <link rel="stylesheet" type="text/css" href="/brandon/styles.css" />
</head>
<body>

<p class="byline">
  by Brandon Rhodes
  • <a title="Home Page" href="/brandon/">Home</a>
</p>
<h1>WSGI and truncated chunked response bodies</h1>
<table class="docinfo" frame="void" rules="none">
<col class="docinfo-name" />
<col class="docinfo-content" />
<tbody valign="top">
<tr><th class="docinfo-name">Date:</th>
<td>14 February 2013</td></tr>
<tr class="field"><th class="docinfo-name">Tags:</th><td class="field-body">computing, python</td>
</tr>
</tbody>
</table>
<p>I may be almost through
with <a class="reference external" href="http://www.python.org/dev/peps/pep-3333/">WSGI</a>.
While it has certainly worked
for a number of my close-to-the-wire HTTP projects over the years,
I seem finally to have reached an edge case where
— as a standard — it cannot guarantee
that I even return a correct response to browsers!</p>
<p>The great triumph of WSGI
is that Python for the Web was suddenly pluggable.
Whether you wrote your application as a raw WSGI callable
or built atop a framework like Django or Pyramid,
you could move from <a class="reference external" href="http://code.google.com/p/modwsgi/">mod_wsgi</a>
running under Apache
to <a class="reference external" href="http://pypi.python.org/pypi/flup/">flup</a> running behind nginx
to <a class="reference external" href="http://gunicorn.org/">gunicorn</a> running on Heroku
without batting an eye or rewriting a single line of code.</p>
<p>The great tragedy of WSGI is its complexity.
Despite the fact that there are code examples inlined into its PEP,
it seems that hardly anyone can put together
a fully correct server or piece of middleware.
Writers like Armin Ronacher and Graham Dumpleton
are good sources of complaints on this subject,
as in Graham's recent pair of posts
<a class="reference external" href="http://blog.dscpl.com.au/2012/10/wsgi-middleware-and-hidden-write.html">WSGI middleware and the hidden write() callable</a>
and <a class="reference external" href="http://blog.dscpl.com.au/2012/10/obligations-for-calling-close-on.html">Obligations for calling close() on the iterable returned by a WSGI application</a>.
The latter article makes the telling observation that,
“Despite the WSGI specification having been around for so long,
one keeps seeing instances where it is implemented wrongly.”
The problem is that WSGI makes a very awkward gesture toward
asynchronicity — an iterable response body — but lets
the application block while doing all of the rest of its work.
The resulting architecture is still completely unusable
by actual async folks like the Twisted or Tornado teams,
while managing to make life awkward for everybody else.
Add in WSGI's other features,
like an obscure synchronous <tt class="docutils literal">write()</tt> call
and the ability of the application to call <tt class="docutils literal">start_response()</tt>
several times if it changes its mind,
and correctness starts to become very difficult to achieve.</p>
<p>The great salvation of WSGI
is that hardly anyone actually has to touch it.
Nearly the entire mass
of the world's busy Python web programmers
are protected from the Terrible Secret of WSGI
by working behind some web framework or other.
This lets WSGI's one great benefit shine —
that servers and applications can be plugged into one other
fairly arbitrarily —
without anyone but framework authors
having to wallow in its complexity
and then attend the Web Summit to vent and recuperate.</p>
<p>But, on to my topic for today.</p>
<p>To my great surprise,
it turns out that — for all its complexity —
WSGI manages to be under-specified!
Consider the following application:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">simple_app</span><span class="p">(</span><span class="n">environ</span><span class="p">,</span> <span class="n">start_response</span><span class="p">):</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;Content-Type&#39;</span><span class="p">,</span> <span class="s">&#39;text/plain&#39;</span><span class="p">)]</span>
    <span class="n">start_response</span><span class="p">(</span><span class="s">&#39;200 OK&#39;</span><span class="p">,</span> <span class="n">headers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">content</span><span class="p">():</span>
        <span class="c"># We start streaming data just fine.</span>
        <span class="k">yield</span> <span class="s">&#39;The dwarves of yore made mighty spells,&#39;</span>
        <span class="k">yield</span> <span class="s">&#39;While hammers fell like ringing bells&#39;</span>

        <span class="c"># Then the back-end fails!</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="mi">1</span><span class="o">/</span><span class="mi">0</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">start_response</span><span class="p">(</span><span class="s">&#39;500 Error&#39;</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">())</span>
            <span class="k">return</span>

        <span class="c"># So rest of the response data is not available.</span>
        <span class="k">yield</span> <span class="s">&#39;In places deep, where dark things sleep,&#39;</span>
        <span class="k">yield</span> <span class="s">&#39;In hollow halls beneath the fells.&#39;</span>

    <span class="k">return</span> <span class="n">content</span><span class="p">()</span></pre></div>

<p>This tiny example manages to exhibit
every essential property of the situation
in which a much larger application has placed me:</p>
<ul class="simple">
<li>My WSGI application returns a generator,
instead of waiting until the entire response has been computed
and returning a list of strings.
First, this protects my application against situations
where the entire response body is larger than RAM —
in which case the approach of queueing strings in a list
would exhaust memory.
And second, it lets the web server
start streaming the response to the client immediately;
an early version of the design that delayed transmission
until the whole response body was ready
often resulted in clients abandoning their connections
before the first byte of the response body could be sent.</li>
<li>The application does not know the content-length of the response
until the final chunk of response body has been generated.</li>
<li>The response body may be impossible to finish generating,
but the application will often not learn this
until it has partially returned the response.
The back-end service for which it is a mediator
may return quite a bit of data before going down,
becoming unresponsive, or returning some kind of error.
Only at that point does the application learn
that it cannot, in fact, return a valid response after all.</li>
</ul>
<p>Many of the resources in play will be cacheable by clients —
some thanks to an <tt class="docutils literal">ETag</tt>
and others thanks to a far-future <tt class="docutils literal">Expires</tt> header.
This means that returning a truncated response
without any indication of failure
not only ruins the client's current attempt to use the resource,
but might render the client <em>permanently</em> unable to proceed
because it might never realize that its cached copy is truncated
and that it needs to re-fetch the resource.</p>
<p>So it is absolutely imperative
that the WSGI server running my application
correctly signal truncated responses to HTTP clients.
There are, to my knowledge, only two ways of doing so.</p>
<p>First, an HTTP server can specify a Content-Length
but then close the socket before sending that much data.
Standards-loving HTTP client libraries
will always recognize failure in this case.
However, one of the limitations that I have already stated
is that I do not know the Content-Length until I have finished
generating and returning the resource, so that is not an option here.</p>
<p>Second, an HTTP server can use chunked encoding
but then close the socket prematurely either
<em>without</em> finishing the current chunk,
or by <em>omitting</em> the concluding zero-length chunk <tt class="docutils literal">0\r\n\r\n</tt>.
An HTTP client will recognize this as a failure
to receive the entire response.</p>
<p>As you can see in the example app above,
I am doing everything right:</p>
<ul class="simple">
<li>I am catching the exception instead of letting it propagate
up into the WSGI server behind me.
While polite WSGI servers will catch exceptions
and return 500 status codes to clients,
there is no guarantee of this,
and some of them will just let your thread crash
and leave a dangling open socket behind them!</li>
<li>I am calling <tt class="docutils literal">start_response()</tt> with the magic third argument
that informs the server, on no uncertain terms,
that I need to terminate the response
because of an exception.</li>
<li>The one dicey aspect of this sample application
is that I am making my second <tt class="docutils literal">start_response()</tt> call
from inside of my generator,
instead of from inside the application function itself.
This is where we get to the part
about WSGI not being entirely fully specified:
it is not entirely clear from the PEP
whether this is how you terminate a generated response body,
because the standard does not quite discuss the issue
of failures that occur after the main callable is complete!</li>
</ul>
<p>So, that is my situation.</p>
<p>I need to stream large responses without knowing their length
and in circumstances where the client receiving the response
body must always be able to recognize a truncated response
so that they do not run off and try to operate upon
the truncated data.</p>
<p>How do four common WSGI servers stack up
when presented with the sample application above?</p>
<ul>
<li><p class="first"><tt class="docutils literal">wsgiref.simple_server</tt> — <strong>Complete disaster!</strong>
When confronted with a generated response body,
<tt class="docutils literal">wsgiref</tt> falls back to primitive HTTP/1.0
that simply appends the response body to the outgoing headers
and then closes the socket upon completion.
When confronted with the early termination of my iterator,
it simply closes the socket early,
making truncated output indistinguishable from a full response.</p>
<div class="highlight"><pre><span class="n">HTTP</span><span class="o">/</span><span class="mf">1.0</span> <span class="mi">200</span> <span class="n">OK</span>
<span class="nl">Date:</span> <span class="n">Fri</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Feb</span> <span class="mi">2013</span> <span class="mo">02</span><span class="o">:</span><span class="mi">31</span><span class="o">:</span><span class="mi">32</span> <span class="n">GMT</span>
<span class="nl">Server:</span> <span class="n">WSGIServer</span><span class="o">/</span><span class="mf">0.1</span> <span class="n">Python</span><span class="o">/</span><span class="mf">2.7.3</span>
<span class="n">Content</span><span class="o">-</span><span class="n">type</span><span class="o">:</span> <span class="n">text</span><span class="o">/</span><span class="n">plain</span>

<span class="n">The</span> <span class="n">dwarves</span> <span class="n">of</span> <span class="n">yore</span> <span class="n">made</span> <span class="n">mighty</span> <span class="n">spells</span><span class="p">,</span>
<span class="n">While</span> <span class="n">hammers</span> <span class="n">fell</span> <span class="n">like</span> <span class="n">ringing</span> <span class="n">bells</span>
<span class="p">[</span><span class="n">SOCKET</span> <span class="n">CLOSES</span><span class="p">]</span></pre></div>

</li>
<li><p class="first"><tt class="docutils literal">gevent.pywsgi</tt> — <strong>Disaster!</strong>
This popular WSGI server fails in a different way.
On the one hand,
it does not create semantic ruin
by delivering what looks like a valid response:
it creates a chunked HTTP/1.1 response
and puts each line of poetry in its own chunk,
and then never finishes the response —
after the second line of data, no further data appears.
So at least clients will not be fooled
into thinking that the response is complete!
But it balances this advantage with a downside:
it actually leaves the socket hanging open indefinitely,
so after this happens enough times
your application will run out of file descriptors and crash.</p>
<div class="highlight"><pre><span class="n">HTTP</span><span class="o">/</span><span class="mf">1.1</span> <span class="mi">200</span> <span class="n">OK</span>
<span class="n">Content</span><span class="o">-</span><span class="n">Type</span><span class="o">:</span> <span class="n">text</span><span class="o">/</span><span class="n">plain</span>
<span class="nl">Date:</span> <span class="n">Fri</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Feb</span> <span class="mi">2013</span> <span class="mo">02</span><span class="o">:</span><span class="mi">33</span><span class="o">:</span><span class="mi">39</span> <span class="n">GMT</span>
<span class="n">Transfer</span><span class="o">-</span><span class="n">Encoding</span><span class="o">:</span> <span class="n">chunked</span>

<span class="mi">27</span>
<span class="n">The</span> <span class="n">dwarves</span> <span class="n">of</span> <span class="n">yore</span> <span class="n">made</span> <span class="n">mighty</span> <span class="n">spells</span><span class="p">,</span>
<span class="mi">25</span>
<span class="n">While</span> <span class="n">hammers</span> <span class="n">fell</span> <span class="n">like</span> <span class="n">ringing</span> <span class="n">bells</span>
<span class="p">[</span><span class="n">SOCKET</span> <span class="n">STAYS</span> <span class="n">OPEN</span> <span class="n">FOREVER</span><span class="p">]</span></pre></div>

</li>
<li><p class="first"><tt class="docutils literal">gunicorn</tt> — <strong>Invalid.</strong>
This is not so bad, though somewhat awkward:
after sending the first two chunks of an HTTP/1.1 chunked response,
Gunicorn decides to throw correctness to the wind
and follow the second chunk with the HTML
of its standard 500 error message!
Following an HTTP chunk with anything but a hexadecimal integer
like <tt class="docutils literal">27\r\n</tt>
is a violation of the protocol and conforming clients
will raise an error — but at least there is no chance
that a client will mistake the response for valid HTTP,
and the socket does get closed and reclaimed.</p>
<div class="highlight"><pre><span class="n">HTTP</span><span class="o">/</span><span class="mf">1.1</span> <span class="mi">200</span> <span class="n">OK</span>
<span class="nl">Server:</span> <span class="n">gunicorn</span><span class="o">/</span><span class="mf">0.17.2</span>
<span class="nl">Date:</span> <span class="n">Fri</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Feb</span> <span class="mi">2013</span> <span class="mo">02</span><span class="o">:</span><span class="mi">35</span><span class="o">:</span><span class="mi">24</span> <span class="n">GMT</span>
<span class="nl">Connection:</span> <span class="n">close</span>
<span class="n">Transfer</span><span class="o">-</span><span class="n">Encoding</span><span class="o">:</span> <span class="n">chunked</span>
<span class="n">Content</span><span class="o">-</span><span class="n">type</span><span class="o">:</span> <span class="n">text</span><span class="o">/</span><span class="n">plain</span>

<span class="mi">27</span>
<span class="n">The</span> <span class="n">dwarves</span> <span class="n">of</span> <span class="n">yore</span> <span class="n">made</span> <span class="n">mighty</span> <span class="n">spells</span><span class="p">,</span>
<span class="mi">25</span>
<span class="n">While</span> <span class="n">hammers</span> <span class="n">fell</span> <span class="n">like</span> <span class="n">ringing</span> <span class="n">bells</span>
<span class="n">HTTP</span><span class="o">/</span><span class="mf">1.1</span> <span class="mi">500</span> <span class="n">Internal</span> <span class="n">Server</span> <span class="n">Error</span>
<span class="nl">Connection:</span> <span class="n">close</span>
<span class="n">Content</span><span class="o">-</span><span class="n">Type</span><span class="o">:</span> <span class="n">text</span><span class="o">/</span><span class="n">html</span>
<span class="n">Content</span><span class="o">-</span><span class="n">Length</span><span class="o">:</span> <span class="mi">134</span>

<span class="o">&lt;</span><span class="n">html</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">head</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">title</span><span class="o">&gt;</span><span class="n">Internal</span> <span class="n">Server</span> <span class="n">Error</span><span class="o">&lt;/</span><span class="n">title</span><span class="o">&gt;</span>
  <span class="o">&lt;/</span><span class="n">head</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">body</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">h1</span><span class="o">&gt;</span><span class="n">Internal</span> <span class="n">Server</span> <span class="n">Error</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>

  <span class="o">&lt;/</span><span class="n">body</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">html</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">SOCKET</span> <span class="n">CLOSES</span><span class="p">]</span></pre></div>

</li>
<li><p class="first"><tt class="docutils literal">cherrypy.wsgiserver</tt> — well, look at that!
Robert Brewer will get a beer from me at PyCon this year,
and CherryPy keeps its reputation as one of the few
production-ready go-to multi-threaded web servers written in Python.
(My own reasons for not using it often is because it does not log
and because I am tired of <tt class="docutils literal">threading</tt> threads,
but that is another story.)
In this case I must admit that it does <strong>everything right:</strong>
it starts with two HTTP/1.1 chunks and then,
when my generator fails,
CherryPy is smart enough to recognize
that the only correct way to signal failure to the client
is to <em>close the socket</em> without further output.</p>
<div class="highlight"><pre><span class="n">HTTP</span><span class="o">/</span><span class="mf">1.1</span> <span class="mi">200</span> <span class="n">OK</span>
<span class="n">Content</span><span class="o">-</span><span class="n">type</span><span class="o">:</span> <span class="n">text</span><span class="o">/</span><span class="n">plain</span>
<span class="n">Transfer</span><span class="o">-</span><span class="n">Encoding</span><span class="o">:</span> <span class="n">chunked</span>
<span class="nl">Date:</span> <span class="n">Fri</span><span class="p">,</span> <span class="mi">15</span> <span class="n">Feb</span> <span class="mi">2013</span> <span class="mo">02</span><span class="o">:</span><span class="mi">37</span><span class="o">:</span><span class="mi">28</span> <span class="n">GMT</span>
<span class="nl">Server:</span> <span class="n">guinness</span>

<span class="mi">27</span>
<span class="n">The</span> <span class="n">dwarves</span> <span class="n">of</span> <span class="n">yore</span> <span class="n">made</span> <span class="n">mighty</span> <span class="n">spells</span><span class="p">,</span>
<span class="mi">25</span>
<span class="n">While</span> <span class="n">hammers</span> <span class="n">fell</span> <span class="n">like</span> <span class="n">ringing</span> <span class="n">bells</span>
<span class="p">[</span><span class="n">SOCKET</span> <span class="n">CLOSES</span><span class="p">]</span></pre></div>

</li>
</ul>
<p>I will probably not use CherryPy in this particular application
because, for other reasons, I am building it upon <tt class="docutils literal">gevent</tt>
and have therefore figured out how to work around
the problems with its <tt class="docutils literal">pywsgi</tt> server
(and will soon be putting those changes together into a pull request).
But it was heartening to see that,
at the very gray edges of the WSGI standard
where HTTP itself needs very careful handling —
since HTTP includes no <em>explicit</em> way to say,
“Wait! Never mind! I cannot finish this response after all!” —
that at least one of the WSGI servers on my short-list
manages to put together
the most utterly correct behavior I can think of.</p>
<p>I will let you know which brand of beer Robert chooses.</p>

    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'rhodesmill';
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
<p class="byline">©2021</p>

</body>
</html>
